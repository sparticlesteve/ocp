trainer: mlperf_forces

dataset:
    - src: /pscratch/sd/s/sfarrell/ocp/data/s2ef/2M/train
      normalize_labels: True
      target_mean: -0.7554450631141663
      target_std: 2.887317180633545
      grad_target_mean: 0.0
      grad_target_std: 2.887317180633545
    - src: /pscratch/sd/s/sfarrell/ocp/data/s2ef/all/val_id

logger: wandb

task:
    mlperf_benchmark: oc20
    mlperf_org: LBNL
    mlperf_division: closed
    mlperf_status: onprem
    mlperf_platform: SUBMISSION_PLATFORM_PLACEHOLDER

    dataset: trajectory_lmdb
    description: "Regressing to energies and forces for DFT trajectories from OCP"
    type: regression
    metric: mae
    primary_metric: forces_mae
    target_forces_mae: 0.036
    labels:
        - potential energy
    grad_input: atomic forces
    train_on_free_atoms: True
    eval_on_free_atoms: True

model:
    name: dimenetplusplus
    hidden_channels: 192
    out_emb_channels: 192
    num_blocks: 3
    cutoff: 6.0
    num_radial: 6
    num_spherical: 7
    num_before_skip: 1
    num_after_skip: 2
    num_output_layers: 3
    regress_forces: True
    use_pbc: True
    #otf_graph: True

# These settings optimized for global batch size (batch_size * gpus) = 256
optim:
    batch_size: 8
    eval_batch_size: 8
    num_workers: 8
    # Evaluate every epoch
    #eval_every: -1000
    lr_initial: 0.0004
    lr_gamma: 0.1

    # New LR schedule based on DistributedSampler partitioning
    lr_milestones:
        - 125008 # 16 epochs
        - 187512 # 24 epochs
        - 250016 # 32 epochs
    warmup_steps: 31252 # 4 epochs

    warmup_factor: 0.2
    max_epochs: 32
    energy_coefficient: 0
    force_coefficient: 50
    disable_tqdm: True

slurm:
    partition: null
    constraint: gpu
    time_min: "4:00:00"
    #account: m1759
    #qos: special
